{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Sense and Sensibility by Jane Austen 1811>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n",
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n",
      "a_pretty am_glad a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "词语索引\n",
    "'''\n",
    "#词的上下文\n",
    "text1.concordance(\"monstrous\")\n",
    "\n",
    "#哪些词出现在相似的上下文中\n",
    "text1.similar(\"monstrous\")\n",
    "\n",
    "#研究两个或两个以上的词共同的上下文\n",
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['Text']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "离散图\n",
    "'''\n",
    "#词在文本中的位置：从文本开头算起在它前面有多少词\n",
    "#每一个竖线代表一个单词，每一行代表整个文本。\n",
    "%matplotlib\n",
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "随机文本\n",
    "'''\n",
    "\n",
    "'''\n",
    "generate() 方法在 NLTK 3.0 中不可用，但会在后续版本中恢复。\n",
    "'''\n",
    "text3.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1.4 词汇计数\n",
    "'''\n",
    "#首先，让我们算出文本从头到尾的长度，包括文本中出现的词和标点符号\n",
    "len=len(text3)\n",
    "\n",
    "#不同的词，得到词汇表\n",
    "set(text3)\n",
    "\n",
    "#排序\n",
    "sorted(set(text3))#一个词汇项的排序表\n",
    "'''\n",
    "词符  表示一个我们想要整体对待的字符序列\n",
    "词类型  指一个词在一个文本中独一无二的出现形式或拼写 \n",
    "—— 也就是说，这个词在词汇表中是唯一的\n",
    "我们计数的2,789 个元素中包括标点符号，所以我们把这些叫做唯一元素类型而不是词类型\n",
    "'''\n",
    "#对文本词汇丰富度进行测量\n",
    "len(set(text3)) / len(text3)\n",
    "\n",
    "#计数一个词在文本中出现的次数，计算一个特定的词在文本中占据的百分比\n",
    "text3.count(\"smote\")\n",
    "100 * text4.count('a') / len(text4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "执行一个任务的代码段叫做一个函数，我们使用关键字def 给函数定义一个简短的名字\n",
    "'''\n",
    "def lexical_diversity(text):\n",
    "    '''\n",
    "    词汇丰富度\n",
    "    '''\n",
    "    return len(set(text)) / len(text)\n",
    "def percentage(count, total):\n",
    "    '''\n",
    "    单词出现次数\n",
    "    '''\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "统计全部文本的基本特征\n",
    "'''\n",
    "print(\"style\\twords\\ttypes\\tlexical_diversity\")\n",
    "for text in [text1,text2,text3。。。]:\n",
    "    print(\"{}\\t{}\\t{}\\t{}\".format())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3.1 频率分布\n",
    "'''\n",
    "#频率分布，它告诉我们在文本中的每一个词项的频率\n",
    "fdist1 = FreqDist(text1)\n",
    "fdist1.most_common(50)\n",
    "fdist1['whale']\n",
    "'''\n",
    "注意\n",
    "轮到你来：使用text2尝试前面的频率分布的例子。注意正确使用括号和大写字母。如果你得到一个错误消息NameError: name 'FreqDist' is not defined，你需要在一开始输入from nltk.book import *\n",
    "'''\n",
    "#词汇的累积频率图\n",
    "fdist1.plot(50, cumulative=True)\n",
    "\n",
    "#只出现一次的词\n",
    "fdist1.hapaxes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3.2 细粒度的选择词\n",
    "'''\n",
    "#找出文本词汇表长度中超过15 个字符的词\n",
    "V = set(text1)\n",
    "long_words = [w for w in V if len(w) > 15]\n",
    "sorted(long_words)\n",
    "\n",
    "#聊天语料库中所有长度超过7 个字符，且出现次数超过7 次的词\n",
    "fdist5 = FreqDist(text5)\n",
    "long_words = [w for w in set(text1) if len(w) > 15 and fdist5[w]>7]\n",
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3.3 词语搭配和双连词\n",
    "'''\n",
    "'''\n",
    "搭配  是异乎寻常地经常在一起出现的词序列\n",
    "搭配的一个特点是其中的词不能被类似的词置换\n",
    "'''\n",
    "#要获取搭配，我们先从提取文本词汇中的词对，也就是双连词开始\n",
    "list(bigrams(['more', 'is', 'said', 'than', 'done']))\n",
    "\n",
    "#搭配基本上就是频繁的双连词，除非我们更加注重包含不常见词的的情况\n",
    "#希望找到比我们基于单个词的频率预期得到的更频繁出现的双连词。collocations() 函数\n",
    "text4.collocations()\n",
    "text8.collocations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3.4 计数其他东西\n",
    "'''\n",
    "#查看文本中 词长 的分布\n",
    "lens_of_words=[len(w) for w in text1]\n",
    "fdist = FreqDist(lens_of_words)\n",
    "print(fdist)\n",
    "\n",
    "#最多出现的次数\n",
    "fdist.max()\n",
    "\n",
    "#出现三次的次数\n",
    "fdist[3]\n",
    "\n",
    "#出现三次的频率\n",
    "fdist.freq(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNLTK 频率分布类中定义的函数\\n\\n示例\\t描述\\nfdist = FreqDist( samples  )\\t创建包含给定样本list,set的频率分布\\nfdist[sample] += 1\\t增加样本的数目\\nfdist['monstrous']\\t计数给定样本出现的次数\\nfdist.freq('monstrous')\\t给定样本的频率\\nfdist.N()\\t样本总数\\nfdist.most_common(n)\\t最常见的n 个样本和它们的频率\\nfor sample in fdist:\\t遍历样本\\nfdist.max()\\t数值最大的样本\\nfdist.tabulate()\\t绘制频率分布表\\nfdist.plot()\\t绘制频率分布图\\nfdist.plot(cumulative=True)\\t绘制累积频率分布图\\nfdist1 |= fdist2\\t使用fdist2 更新fdist1 中的数目\\nfdist1 < fdist2\\t测试样本在fdist1 中出现的频率是否小于fdist2\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "NLTK 频率分布类中定义的函数\n",
    "\n",
    "示例\t描述\n",
    "fdist = FreqDist( samples  )\t创建包含给定样本list,set的频率分布\n",
    "fdist[sample] += 1\t增加样本的数目\n",
    "fdist['monstrous']\t计数给定样本出现的次数\n",
    "fdist.freq('monstrous')\t给定样本的频率\n",
    "fdist.N()\t样本总数\n",
    "fdist.most_common(n)\t最常见的n 个样本和它们的频率\n",
    "for sample in fdist:\t遍历样本\n",
    "fdist.max()\t数值最大的样本\n",
    "fdist.tabulate()\t绘制频率分布表\n",
    "fdist.plot()\t绘制频率分布图\n",
    "fdist.plot(cumulative=True)\t绘制累积频率分布图\n",
    "fdist1 |= fdist2\t使用fdist2 更新fdist1 中的数目\n",
    "fdist1 < fdist2\t测试样本在fdist1 中出现的频率是否小于fdist2\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n一些词比较运算符\\n\\n函数\\t含义\\ns.startswith(t)\\t测试s是否以t 开头\\ns.endswith(t)\\t测试s是否以t 结尾\\nt in s\\t测试t是否是s的子串\\ns.islower()\\t测试s中所有字符是否包含大小有区别的字符，且都是小写\\ns.isupper()\\t测试s中所有字符是否包含大小有区别的字符，且都是大写\\ns.isalpha()\\t测试s是否非空，且s中的所有字符是字母\\ns.isalnum()\\t测试s是否非空，且s中的所有字符是字母或数字\\ns.isdigit()\\t测试s是否非空，且s 中的所有字符都是数字\\ns.istitle()\\t测试s是否包含大小有区别的字符，且首字母大写（即，s中所有的词都首字母大写）\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "一些词比较运算符\n",
    "\n",
    "函数\t含义\n",
    "s.startswith(t)\t测试s是否以t 开头\n",
    "s.endswith(t)\t测试s是否以t 结尾\n",
    "t in s\t测试t是否是s的子串\n",
    "s.islower()\t测试s中所有字符是否包含大小有区别的字符，且都是小写\n",
    "s.isupper()\t测试s中所有字符是否包含大小有区别的字符，且都是大写\n",
    "s.isalpha()\t测试s是否非空，且s中的所有字符是字母\n",
    "s.isalnum()\t测试s是否非空，且s中的所有字符是字母或数字\n",
    "s.isdigit()\t测试s是否非空，且s 中的所有字符都是数字\n",
    "s.istitle()\t测试s是否包含大小有区别的字符，且首字母大写（即，s中所有的词都首字母大写）\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWord Sense Disambiguation\\n词意消歧\\n在词意消歧中，我们要算出特定上下文中的词被赋予的是哪个意思。\\n换句话说，自动消除歧义需要使用上下文，利用相邻词汇有相近含义这样一个简单的事实。\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Word Sense Disambiguation\n",
    "词意消歧\n",
    "在词意消歧中，我们要算出特定上下文中的词被赋予的是哪个意思。\n",
    "换句话说，自动消除歧义需要使用上下文，利用相邻词汇有相近含义这样一个简单的事实。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPronoun Resolution\\n指代消解\\n\\nthe thieves stole the paintings\\n一种更深刻的语言理解是解决“谁对谁做了什么”，即检测动词的主语和宾语\\n要回答这个问题涉及到寻找代词they的先行词，thieves或者paintings。处理这个问题的计算技术包括指代消解 ——确定代词或名词短语指的是什么—— 和语义角色标注 —— 确定名词短语如何与动词相关联（如施事，受事，工具等）。\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Pronoun Resolution\n",
    "指代消解\n",
    "\n",
    "the thieves stole the paintings\n",
    "一种更深刻的语言理解是解决“谁对谁做了什么”，即检测动词的主语和宾语\n",
    "要回答这个问题涉及到寻找代词they的先行词，thieves或者paintings。处理这个问题的计算技术包括指代消解 ——确定代词或名词短语指的是什么—— 和语义角色标注 —— 确定名词短语如何与动词相关联（如施事，受事，工具等）。\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generating Language Output\n",
    "自动生成语言\n",
    "\n",
    "如自动问答和机器翻译\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Textual Entailment\n",
    "文本的含义\n",
    "RTE\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n小结\\n在Python 中文本用列表来表示：['Monty', 'Python']。我们可以使用索引、分片和len()函数对列表进行操作。\\n“词符”是指文本中给定词的特定出现；“词型”则是指词作为一个特定序列字母的唯一形式。我们使用len(text)计数词符，使用len(set(text))计数词型。\\n我们使用 using sorted(set(t))获得文本t的词汇表。\\n我们使用[f(x) for x in text]对文本的每一项目进行操作。\\n为了获得没有大小写区分和忽略标点符号的词汇表，我们可以写成set(w.lower() for w in text if w.isalpha())。\\n我们使用for语句对文本中的每个词进行处理，例如for w in t: 或for word in text:。后面必须跟冒号和一块在每次循环被执行的缩进的代码。\\n我们使用if语句测试一个条件：if len(word) < 5:。后面必须跟冒号和一块仅当条件为真时执行的缩进的代码。\\n频率分布是元素连同它们的频率计数的集合(例如：一个文本中的词与它们出现的频率)。\\n函数是指定了名字并且可以重用的代码块。函数通过def关键字定义，例如def mult(x, y)；x和y是函数的参数，起到实际数据值的占位符的作用。\\n函数是通过指定它的名字及一个或多个放在括号里的实参来调用，就像这样：texts(), mult(3, 4), len(text1)。\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "小结\n",
    "在Python 中文本用列表来表示：['Monty', 'Python']。我们可以使用索引、分片和len()函数对列表进行操作。\n",
    "“词符”是指文本中给定词的特定出现；“词型”则是指词作为一个特定序列字母的唯一形式。我们使用len(text)计数词符，使用len(set(text))计数词型。\n",
    "我们使用 using sorted(set(t))获得文本t的词汇表。\n",
    "我们使用[f(x) for x in text]对文本的每一项目进行操作。\n",
    "为了获得没有大小写区分和忽略标点符号的词汇表，我们可以写成set(w.lower() for w in text if w.isalpha())。\n",
    "我们使用for语句对文本中的每个词进行处理，例如for w in t: 或for word in text:。后面必须跟冒号和一块在每次循环被执行的缩进的代码。\n",
    "我们使用if语句测试一个条件：if len(word) < 5:。后面必须跟冒号和一块仅当条件为真时执行的缩进的代码。\n",
    "频率分布是元素连同它们的频率计数的集合(例如：一个文本中的词与它们出现的频率)。\n",
    "函数是指定了名字并且可以重用的代码块。函数通过def关键字定义，例如def mult(x, y)；x和y是函数的参数，起到实际数据值的占位符的作用。\n",
    "函数是通过指定它的名字及一个或多个放在括号里的实参来调用，就像这样：texts(), mult(3, 4), len(text1)。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
