{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n我们如何使用形式化语法来描述无限的句子集合的结构？\\n我们如何使用句法树来表示句子结构？\\n语法分析器如何分析一个句子并自动构建句法树？\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "我们如何使用形式化语法来描述无限的句子集合的结构？\n",
    "我们如何使用句法树来表示句子结构？\n",
    "语法分析器如何分析一个句子并自动构建句法树？\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1 一些语法困境\\n\\n1.1 语言数据和无限可能性\\n'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1 一些语法困境\n",
    "\n",
    "1.1 语言数据和无限可能性\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n文法的目的是给出一个明确的语言描述。\\n\\n\\n'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "文法的目的是给出一个明确的语言描述。\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1.2 普遍存在的歧义\\n'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1.2 普遍存在的歧义\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个文法允许以两种方式分析句子，取决于介词短语in my pajamas是描述大象还是枪击事件\n",
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(groucho_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "程序产生两个括号括起的结构，我们可以用树来表示它们\n",
    "请注意，相关的所有词的含义是没有歧义的；例如词shot不会在第一句话中表示使用枪的动作，而在第二句中表示使用相机。\n",
    "'''\n",
    "for tree in parser.parse(sent):\n",
    "     print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2 句法的用处是什么？\\n\\n'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2 句法的用处是什么？\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n2.1 超越n-grams\\n\\n'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "2.1 超越n-grams\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n成分结构\\n成分结构基于对词与其他词结合在一起形成单元的观察。\\n\\n一个词序列形成这样一个单元的证据是它是可替代的——也就是说，\\n在一个符合语法规则的句子中的词序列可以被一个更小的序列替代而不会导致句子不符合语法规则。\\n'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "成分结构\n",
    "成分结构基于对词与其他词结合在一起形成单元的观察。\n",
    "\n",
    "一个词序列形成这样一个单元的证据是它是可替代的——也就是说，\n",
    "在一个符合语法规则的句子中的词序列可以被一个更小的序列替代而不会导致句子不符合语法规则。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n树的每个节点（包括词）被称为一个成分。S的直接成分是NP和VP。\\n'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "树的每个节点（包括词）被称为一个成分。S的直接成分是NP和VP。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3 上下文无关语法\\n'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3 上下文无关语法\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3.1 一个简单的语法\\n\\n首先，让我们看一个简单的上下文无关语法。\\n按照惯例，第一条生产式的左端是语法的开始符号，通常是S，所有符合语法规则的树都必须有这个符号作为它们的根标签\\n\\n在NLTK中，上下文无关语法定义在nltk.grammar模块\\n\\n'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3.1 一个简单的语法\n",
    "\n",
    "首先，让我们看一个简单的上下文无关语法。\n",
    "按照惯例，第一条生产式的左端是语法的开始符号，通常是S，所有符合语法规则的树都必须有这个符号作为它们的根标签\n",
    "\n",
    "在NLTK中，上下文无关语法定义在nltk.grammar模块\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "  S -> NP VP\n",
    "  VP -> V NP | V NP PP\n",
    "  PP -> P NP\n",
    "  V -> \"saw\" | \"ate\" | \"walked\"\n",
    "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Mary saw Bob\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n句法类型\\n\\n符号\\t含义\\t示例\\nS\\t句子\\tthe man walked\\nNP\\t名词短语\\ta dog\\nVP\\t动词短语\\tsaw a park\\nPP\\t介词短语\\twith a telescope\\nDet\\t限定词\\tthe\\nN\\t名词\\tdog\\nV\\t动词\\twalked\\nP\\t介词\\tin\\n\\n'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "句法类型\n",
    "\n",
    "符号\t含义\t示例\n",
    "S\t句子\tthe man walked\n",
    "NP\t名词短语\ta dog\n",
    "VP\t动词短语\tsaw a park\n",
    "PP\t介词短语\twith a telescope\n",
    "Det\t限定词\tthe\n",
    "N\t名词\tdog\n",
    "V\t动词\twalked\n",
    "P\t介词\tin\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n产生式如VP -> V NP | V NP PP右侧脱节了，中间显示|，这是两个产生式VP -> V NP和VP -> V NP PP的缩写。\\n'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "产生式如VP -> V NP | V NP PP右侧脱节了，中间显示|，这是两个产生式VP -> V NP和VP -> V NP PP的缩写。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n递归下降分析器\\nnltk.app.rdparser()\\n'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "递归下降分析器\n",
    "nltk.app.rdparser()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.app.rdparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3.2 编写你自己的文法\\n\\n如果你有兴趣尝试写上下文无关语法CFG，你会发现在一个文本文件mygrammar.cfg中创建和编辑你的语法会很有帮助。然后，你可以加载它到NLTK 中，并按如下方式用它进行分析：\\n\\n>>> grammar1 = nltk.data.load(\\'file:mygrammar.cfg\\')\\n>>> sent = \"Mary saw Bob\".split()\\n>>> rd_parser = nltk.RecursiveDescentParser(grammar1)\\n>>> for tree in rd_parser.parse(sent):\\n...      print(tree)\\n\\n\\n确保你的文件名后缀为.cfg，并且字符串\\'file:mygrammar.cfg\\'中间没有空格符。\\n\\n如果命令print(tree)没有产生任何输出，这可能是因为你的句子sent并不符合你的语法。在这种情况下，可以将分析器的跟踪设置打开：rd_parser = nltk.RecursiveDescentParser(grammar1, trace=2)。你还可以查看当前使用的语法中的产生式，使用命令for p in grammar1.productions(): print(p)。\\n\\n你编写CFG在NLTK中分析时，你不能将语法类型与词汇项目一起写在同一个产生式的右侧。因此，产生式PP -> \\'of\\' NP是不允许的。另外，你不得在产生式右侧仿制多个词的词汇项。因此，不能写成NP -> \\'New York\\'，而要写成类似NP -> \\'New_York\\'这样的。\\n'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3.2 编写你自己的文法\n",
    "\n",
    "如果你有兴趣尝试写上下文无关语法CFG，你会发现在一个文本文件mygrammar.cfg中创建和编辑你的语法会很有帮助。然后，你可以加载它到NLTK 中，并按如下方式用它进行分析：\n",
    "\n",
    ">>> grammar1 = nltk.data.load('file:mygrammar.cfg')\n",
    ">>> sent = \"Mary saw Bob\".split()\n",
    ">>> rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    ">>> for tree in rd_parser.parse(sent):\n",
    "...      print(tree)\n",
    "\n",
    "\n",
    "确保你的文件名后缀为.cfg，并且字符串'file:mygrammar.cfg'中间没有空格符。\n",
    "\n",
    "如果命令print(tree)没有产生任何输出，这可能是因为你的句子sent并不符合你的语法。在这种情况下，可以将分析器的跟踪设置打开：rd_parser = nltk.RecursiveDescentParser(grammar1, trace=2)。你还可以查看当前使用的语法中的产生式，使用命令for p in grammar1.productions(): print(p)。\n",
    "\n",
    "你编写CFG在NLTK中分析时，你不能将语法类型与词汇项目一起写在同一个产生式的右侧。因此，产生式PP -> 'of' NP是不允许的。另外，你不得在产生式右侧仿制多个词的词汇项。因此，不能写成NP -> 'New York'，而要写成类似NP -> 'New_York'这样的。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3.3 句法结构中的递归\\n'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3.3 句法结构中的递归\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n分析器根据语法产生式处理输入的句子，并建立一个或多个符合语法的组成结构。语法是一个格式良好的声明规范——它实际上只是一个字符串，而不是程序。分析器是语法的解释程序。它搜索符合语法的所有树的空间找出一棵边缘有所需句子的树。\\n\\n\\n一种自上而下的方法称为递归下降分析，一种自下而上的方法称为移进-归约分析。我们也将看到一些更复杂的算法，一种带自下而上过滤的自上而下的方法称为左角落分析；一种动态规划技术称为图表分析。\\n'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "分析器根据语法产生式处理输入的句子，并建立一个或多个符合语法的组成结构。语法是一个格式良好的声明规范——它实际上只是一个字符串，而不是程序。分析器是语法的解释程序。它搜索符合语法的所有树的空间找出一棵边缘有所需句子的树。\n",
    "\n",
    "\n",
    "一种自上而下的方法称为递归下降分析，一种自下而上的方法称为移进-归约分析。我们也将看到一些更复杂的算法，一种带自下而上过滤的自上而下的方法称为左角落分析；一种动态规划技术称为图表分析。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n4.1 递归下降分析\\n一种最简单的分析器将一个语法作为如何将一个高层次的目标分解成几个低层次的子目标的规范来解释。\\n\\n顶层的目标是找到一个S。S → NP VP生产式允许分析器替换这个目标为两个子目标：找到一个NP，然后找到一个VP。每个这些子目标都可以再次被子目标的子目标替代，使用左侧有NP和VP的产生式。最终，这种扩张过程达到子目标\\n\\n\\n递归下降分析器在上述过程中建立分析树。带着最初的目标（找到一个S），创建S根节点。随着上述过程使用文法的产生式递归扩展，分析树不断向下延伸（故名为递归下降）。我们可以在图形化示范nltk.app.rdparser()中看到这个过程。\\n\\n\\n递归下降分析器的六个阶段：分析器以一颗包含节点S的树开始；每个阶段它会查询文法来找到一个可以用于扩大树的产生式；当遇到一个词汇产生式时，将它的词与输入比较；发现一个完整的分析树后，分析器会回溯寻找更多的分析树。\\n'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4.1 递归下降分析\n",
    "一种最简单的分析器将一个语法作为如何将一个高层次的目标分解成几个低层次的子目标的规范来解释。\n",
    "\n",
    "顶层的目标是找到一个S。S → NP VP生产式允许分析器替换这个目标为两个子目标：找到一个NP，然后找到一个VP。每个这些子目标都可以再次被子目标的子目标替代，使用左侧有NP和VP的产生式。最终，这种扩张过程达到子目标\n",
    "\n",
    "\n",
    "递归下降分析器在上述过程中建立分析树。带着最初的目标（找到一个S），创建S根节点。随着上述过程使用文法的产生式递归扩展，分析树不断向下延伸（故名为递归下降）。我们可以在图形化示范nltk.app.rdparser()中看到这个过程。\n",
    "\n",
    "\n",
    "递归下降分析器的六个阶段：分析器以一颗包含节点S的树开始；每个阶段它会查询文法来找到一个可以用于扩大树的产生式；当遇到一个词汇产生式时，将它的词与输入比较；发现一个完整的分析树后，分析器会回溯寻找更多的分析树。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNLTK提供一个递归下降分析器：\\n\\n>>> rd_parser = nltk.RecursiveDescentParser(grammar1)\\n>>> sent = 'Mary saw a dog'.split()\\n>>> for tree in rd_parser.parse(sent):\\n...     print(tree)\\n(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\\n\\n\\n\""
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "NLTK提供一个递归下降分析器：\n",
    "\n",
    ">>> rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    ">>> sent = 'Mary saw a dog'.split()\n",
    ">>> for tree in rd_parser.parse(sent):\n",
    "...     print(tree)\n",
    "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n递归下降分析是一种自上而下分析。自上而下分析器在检查输入之前先使用文法预测输入将是什么！然而，由于输入对分析器一直是可用的，从一开始就考虑输入的句子会是更明智的做法。这种方法被称为自下而上分析，在下一节中我们将看到一个例子。\\n\\n\\n'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "递归下降分析是一种自上而下分析。自上而下分析器在检查输入之前先使用文法预测输入将是什么！然而，由于输入对分析器一直是可用的，从一开始就考虑输入的句子会是更明智的做法。这种方法被称为自下而上分析，在下一节中我们将看到一个例子。\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n4.2 移进-归约分析\\n\\n一种简单的自下而上分析器是移进-归约分析器。与所有自下而上的分析器一样，移进-归约分析器尝试找到对应文法生产式右侧的词和短语的序列，用左侧的替换它们，直到整个句子归约为一个S。\\n\\n移位-规约分析器反复将下一个输入词推到堆栈（4.1）；这是移位操作。如果堆栈上的前n项，匹配一些产生式的右侧的n个项目，那么就把它们弹出栈，并把产生式左边的项目压入栈。这种替换前n项为一项的操作就是规约操作。此操作只适用于堆栈的顶部；规约栈中的项目必须在后面的项目被压入栈之前做。当所有的输入都使用过，堆栈中只剩余一个项目，也就是一颗分析树作为它的根的S节点时，分析器完成。移位-规约分析器通过上述过程建立一颗分析树。每次弹出堆栈n个项目，它就将它们组合成部分的分析树，然后将这压回推栈。我们可以使用图形化示范nltk.app.srparser()看到移位-规约分析算法步骤。执行此分析器的六个阶段，如4.2所示。\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4.2 移进-归约分析\n",
    "\n",
    "一种简单的自下而上分析器是移进-归约分析器。与所有自下而上的分析器一样，移进-归约分析器尝试找到对应文法生产式右侧的词和短语的序列，用左侧的替换它们，直到整个句子归约为一个S。\n",
    "\n",
    "移位-规约分析器反复将下一个输入词推到堆栈（4.1）；这是移位操作。如果堆栈上的前n项，匹配一些产生式的右侧的n个项目，那么就把它们弹出栈，并把产生式左边的项目压入栈。这种替换前n项为一项的操作就是规约操作。此操作只适用于堆栈的顶部；规约栈中的项目必须在后面的项目被压入栈之前做。当所有的输入都使用过，堆栈中只剩余一个项目，也就是一颗分析树作为它的根的S节点时，分析器完成。移位-规约分析器通过上述过程建立一颗分析树。每次弹出堆栈n个项目，它就将它们组合成部分的分析树，然后将这压回推栈。我们可以使用图形化示范nltk.app.srparser()看到移位-规约分析算法步骤。执行此分析器的六个阶段，如4.2所示。\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n移进-归约分析器的六个阶段：分析器一开始把输入的第一个词转移到堆栈；一旦堆栈顶端的项目与一个文法产生式的右侧匹配，就可以将它们用那个产生式的左侧替换；当所有输入都被使用过且堆栈中只有剩余一个项目S时，分析成功。\\n'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "移进-归约分析器的六个阶段：分析器一开始把输入的第一个词转移到堆栈；一旦堆栈顶端的项目与一个文法产生式的右侧匹配，就可以将它们用那个产生式的左侧替换；当所有输入都被使用过且堆栈中只有剩余一个项目S时，分析成功。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNLTK中提供ShiftReduceParser()，移进-归约分析器的一个简单的实现。这个分析器不执行任何回溯，所以它不能保证一定能找到一个文本的解析，即使确实存在一个这样的解析。此外，它最多只会找到一个解析，即使有多个解析存在。我们可以提供一个可选的trace参数，控制分析器报告它分析一个文本的步骤的繁琐程度。\\n\\n>>> sr_parser = nltk.ShiftReduceParser(grammar1)\\n>>> sent = 'Mary saw a dog'.split()\\n>>> for tree in sr_parser.parse(sent):\\n...     print(tree)\\n  (S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\\n\\n\""
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "NLTK中提供ShiftReduceParser()，移进-归约分析器的一个简单的实现。这个分析器不执行任何回溯，所以它不能保证一定能找到一个文本的解析，即使确实存在一个这样的解析。此外，它最多只会找到一个解析，即使有多个解析存在。我们可以提供一个可选的trace参数，控制分析器报告它分析一个文本的步骤的繁琐程度。\n",
    "\n",
    ">>> sr_parser = nltk.ShiftReduceParser(grammar1)\n",
    ">>> sent = 'Mary saw a dog'.split()\n",
    ">>> for tree in sr_parser.parse(sent):\n",
    "...     print(tree)\n",
    "  (S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n5 依存关系和依存文法\\n\\n'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "尝试交互式图表分析器应用程序nltk.app.chartparser()。\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "5 依存关系和依存文法\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n短语结构文法是关于词和词序列如何结合起来形成句子成分的。\\n一个独特的和互补的方式，\\n依存语法，集中关注的是词与其他词之间的关系。\\n依存关系是一个中心词与它的依赖之间的二元对称关系。一个句子的中心词通常是动词，所有其他词要么依赖于中心词，要么依赖路径与它联通。\\n\\n一个句子的中心词通常是动词，所有其他词要么依赖于中心词，要么依赖路径与它联通。5.1显示一个依存关系图，箭头从中心词指出它们的依赖。\\n\\n\\n与短语结构语法相比，依存语法可以作为一种依存关系直接用来表示语法功能\\n\\n面是NLTK为依存语法编码的一种方式——注意它只能捕捉依存关系信息，不能指定依存关系类型\\n'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "短语结构文法是关于词和词序列如何结合起来形成句子成分的。\n",
    "一个独特的和互补的方式，\n",
    "依存语法，集中关注的是词与其他词之间的关系。\n",
    "依存关系是一个中心词与它的依赖之间的二元对称关系。一个句子的中心词通常是动词，所有其他词要么依赖于中心词，要么依赖路径与它联通。\n",
    "\n",
    "一个句子的中心词通常是动词，所有其他词要么依赖于中心词，要么依赖路径与它联通。5.1显示一个依存关系图，箭头从中心词指出它们的依赖。\n",
    "\n",
    "\n",
    "与短语结构语法相比，依存语法可以作为一种依存关系直接用来表示语法功能\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNLTK为依存语法编码的一种方式——注意它只能捕捉依存关系信息，不能指定依存关系类型\\n'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "NLTK为依存语法编码的一种方式——注意它只能捕捉依存关系信息，不能指定依存关系类型\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_dep_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "... 'shot' -> 'I' | 'elephant' | 'in'\n",
    "... 'elephant' -> 'an' | 'in'\n",
    "... 'in' -> 'pajamas'\n",
    "... 'pajamas' -> 'my'\n",
    "... \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 7 productions\n",
      "  'shot' -> 'I'\n",
      "  'shot' -> 'elephant'\n",
      "  'shot' -> 'in'\n",
      "  'elephant' -> 'an'\n",
      "  'elephant' -> 'in'\n",
      "  'in' -> 'pajamas'\n",
      "  'pajamas' -> 'my'\n"
     ]
    }
   ],
   "source": [
    "print(groucho_dep_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n7 小结\\n句子都有内部组织结构，可以用一棵树表示。组成结构的显著特点是：递归、中心词、补语和修饰语。\\n语法是一个潜在的无限的句子集合的一个紧凑的特性；我们说，一棵树是符合语法规则的或语法树授权一棵树。\\n语法是用于描述一个给定的短语是否可以被分配一个特定的成分或依赖结构的一种形式化模型。\\n给定一组句法类别，上下文无关文法使用一组生产式表示某类型A的短语如何能够被分析成较小的序列α1 ... αn。\\n依存语法使用产生式指定给定的中心词的依赖是什么。\\n一个句子有一个以上的句法分析就产生句法歧义（如介词短语附着歧义）。\\n分析器是一个过程，为符合语法规则的句子寻找一个或多个相应的树。\\n一个简单的自上而下分析器是递归下降分析器，在语法产生式的帮助下递归扩展开始符号（通常是S），尝试匹配输入的句子。这个分析器并不能处理左递归产生式（如NP -> NP PP）。它盲目扩充类别而不检查它们是否与输入字符串兼容的方式效率低下，而且会重复扩充同样的非终结符然后丢弃结果。\\n一个简单的自下而上的分析器是移位-规约分析器，它把输入移到一个堆栈中，并尝试匹配堆栈顶部的项目和语法产生式右边的部分。这个分析器不能保证为输入找到一个有效的解析，即使它确实存在，它建立子结构而不检查它是否与全部语法一致。\\n\\n'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n概率上下文无关语法（或PCFG）是一种上下文无关语法，它的每一个产生式关联一个概率。它会产生与相应的上下文无关语法相同的文本解析，并给每个解析分配一个概率。PCFG产生的一个解析的概率仅仅是它用到的产生式的概率的乘积。\\n\\n最简单的方法定义一个PCFG 是从一个加权产生式序列组成的特殊格式的字符串加载它，其中权值出现在括号里\\n\\n'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n5.1 配价与词汇\\n5.2 扩大规模\\n'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "5.1 配价与词汇\n",
    "5.2 扩大规模\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n6 语法开发\\n\\n6.1 树库和语法\\n6.2 有害的歧义\\n6.3 加权语法\\n'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "6 语法开发\n",
    "\n",
    "6.1 树库和语法\n",
    "6.2 有害的歧义\n",
    "6.3 加权语法\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n概率上下文无关语法（或PCFG）是一种上下文无关语法，它的每一个产生式关联一个概率。它会产生与相应的上下文无关语法相同的文本解析，并给每个解析分配一个概率。PCFG产生的一个解析的概率仅仅是它用到的产生式的概率的乘积。\\n\\n最简单的方法定义一个PCFG 是从一个加权产生式序列组成的特殊格式的字符串加载它，其中权值出现在括号里\\n\\n'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "概率上下文无关语法（或PCFG）是一种上下文无关语法，它的每一个产生式关联一个概率。它会产生与相应的上下文无关语法相同的文本解析，并给每个解析分配一个概率。PCFG产生的一个解析的概率仅仅是它用到的产生式的概率的乘积。\n",
    "\n",
    "最简单的方法定义一个PCFG 是从一个加权产生式序列组成的特殊格式的字符串加载它，其中权值出现在括号里\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n7 小结\\n句子都有内部组织结构，可以用一棵树表示。组成结构的显著特点是：递归、中心词、补语和修饰语。\\n语法是一个潜在的无限的句子集合的一个紧凑的特性；我们说，一棵树是符合语法规则的或语法树授权一棵树。\\n语法是用于描述一个给定的短语是否可以被分配一个特定的成分或依赖结构的一种形式化模型。\\n给定一组句法类别，上下文无关文法使用一组生产式表示某类型A的短语如何能够被分析成较小的序列α1 ... αn。\\n依存语法使用产生式指定给定的中心词的依赖是什么。\\n一个句子有一个以上的句法分析就产生句法歧义（如介词短语附着歧义）。\\n分析器是一个过程，为符合语法规则的句子寻找一个或多个相应的树。\\n一个简单的自上而下分析器是递归下降分析器，在语法产生式的帮助下递归扩展开始符号（通常是S），尝试匹配输入的句子。这个分析器并不能处理左递归产生式（如NP -> NP PP）。它盲目扩充类别而不检查它们是否与输入字符串兼容的方式效率低下，而且会重复扩充同样的非终结符然后丢弃结果。\\n一个简单的自下而上的分析器是移位-规约分析器，它把输入移到一个堆栈中，并尝试匹配堆栈顶部的项目和语法产生式右边的部分。这个分析器不能保证为输入找到一个有效的解析，即使它确实存在，它建立子结构而不检查它是否与全部语法一致。\\n\\n'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "7 小结\n",
    "句子都有内部组织结构，可以用一棵树表示。组成结构的显著特点是：递归、中心词、补语和修饰语。\n",
    "语法是一个潜在的无限的句子集合的一个紧凑的特性；我们说，一棵树是符合语法规则的或语法树授权一棵树。\n",
    "语法是用于描述一个给定的短语是否可以被分配一个特定的成分或依赖结构的一种形式化模型。\n",
    "给定一组句法类别，上下文无关文法使用一组生产式表示某类型A的短语如何能够被分析成较小的序列α1 ... αn。\n",
    "依存语法使用产生式指定给定的中心词的依赖是什么。\n",
    "一个句子有一个以上的句法分析就产生句法歧义（如介词短语附着歧义）。\n",
    "分析器是一个过程，为符合语法规则的句子寻找一个或多个相应的树。\n",
    "一个简单的自上而下分析器是递归下降分析器，在语法产生式的帮助下递归扩展开始符号（通常是S），尝试匹配输入的句子。这个分析器并不能处理左递归产生式（如NP -> NP PP）。它盲目扩充类别而不检查它们是否与输入字符串兼容的方式效率低下，而且会重复扩充同样的非终结符然后丢弃结果。\n",
    "一个简单的自下而上的分析器是移位-规约分析器，它把输入移到一个堆栈中，并尝试匹配堆栈顶部的项目和语法产生式右边的部分。这个分析器不能保证为输入找到一个有效的解析，即使它确实存在，它建立子结构而不检查它是否与全部语法一致。\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
